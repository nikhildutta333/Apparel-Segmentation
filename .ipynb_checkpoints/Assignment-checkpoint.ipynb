{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apparel Segmentation and Dominant Color detection\n",
    "\n",
    "#### The following approach makes use of OpenCV, Numpy, Pandas and Scikit libraries to segment the apparel and find the dominant color.  \n",
    "\n",
    "#### Let's import the necessary libraries for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import operator\n",
    "import math\n",
    "import struct\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define some functions for creating the histogram and plot colors in it which we will use to view dominant colors of the apparel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    # return the histogram\n",
    "    return hist\n",
    "\n",
    "def plot_colors(hist, centroids):\n",
    "    # initialize the bar chart representing the relative frequency\n",
    "    # of each of the colors\n",
    "    bar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    # loop over the percentage of each cluster and the color of\n",
    "    # each cluster\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some inititalizations for performing operations on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddepth = cv2.CV_16S\n",
    "scale = 1\n",
    "delta = 0\n",
    "\n",
    "filedir ='inputs/'\n",
    "fileout= 'outputs/'\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "\n",
    "if not os.path.exists(fileout):\n",
    "    os.makedirs(fileout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to process every image in the input files and store them in the output file along with the histogram of dominant colors in the segmented image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0.6857549628744305], [3, 0.610134351355328], [4, 0.6093647163013246], [5, 0.5348511169892737], [6, 0.47909092354011784], [7, 0.4372016934666475]]\n",
      "[[5, 0.6103361766274554], [3, 0.5985329131862974], [2, 0.5972404919148501], [4, 0.5533939492171371], [6, 0.5337558345296265], [7, 0.5322618305469857]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in glob.glob(os.path.join(filedir,\"*\")):\n",
    "    \n",
    "    f2=os.path.splitext(f)[0]\n",
    "    f2 = os.path.split(f2)[1]\n",
    "    \n",
    "    img= cv2.imread(f)\n",
    "    temp=cv2.imread(f)\n",
    "    img2= cv2.imread(f)\n",
    "    img3= cv2.imread(f)\n",
    "    \n",
    "    #we use bg_color to make this the default pixels for replacing skin pixels after removing them from the spot. \n",
    "    bg_color=img[0][0]\n",
    "\n",
    "    temp=cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h,w=img.shape[0:2]\n",
    "    img2=cv2.rectangle(img2,(0,0),(w,h),(255,255,255),-1)\n",
    "\n",
    "    # Constants for finding range of skin color in YCrCb and extract the pixels without the skin tone\n",
    "    min_YCrCb = np.array([0,123,77],np.uint8)\n",
    "    max_YCrCb = np.array([255,173,130],np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    # Convert image to YCrCb\n",
    "    imageYCrCb = cv2.cvtColor(temp,cv2.COLOR_RGB2YCR_CB)\n",
    "\n",
    "    # Find region with skin tone in YCrCb image\n",
    "    skinRegion = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    skinRegion = cv2.erode(skinRegion, kernel, iterations = 3)\n",
    "    skinRegion = cv2.dilate(skinRegion, kernel, iterations = 3)\n",
    "\n",
    "    skinRegion = cv2.GaussianBlur(skinRegion, (3, 3), 0)\n",
    "\n",
    "    skinRegion=255-skinRegion\n",
    "\n",
    "    skin = cv2.bitwise_and(img, img, mask = skinRegion)\n",
    "\n",
    "    skin[np.where((skin == [0,0,0]).all(axis = 2))] = bg_color\n",
    "\n",
    "    cv2.imwrite('Foreground.png', skin)\n",
    "\n",
    "    skin = cv2.Canny(skin,100,500)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    skin = cv2.dilate(skin, kernel, iterations=2)\n",
    "\n",
    "    skin = cv2.Canny(skin,100,500)\n",
    "    skin = cv2.dilate(skin, kernel, iterations=1)\n",
    "    skin = cv2.erode(skin, kernel, iterations=1)\n",
    "    \n",
    "    cnts, _ = cv2.findContours(skin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "    \n",
    "    # This code segment will help us prepare mask for our apparel segmentation,we use output from skin to create a \n",
    "    # mask. img2 is the blank image we have in which we will draw contours and prepare mask for area we seperated \n",
    "    #from skin to get the apparel\n",
    "    \n",
    "    \n",
    "    cv2.drawContours(img2, c, -1, (0,0,0), thickness=0)\n",
    "    th, img2 = cv2.threshold(img2, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "    im_floodfill = img2.copy()\n",
    "    h, w = img2.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the foreground.\n",
    "    im_out = img2 | im_floodfill_inv\n",
    "\n",
    "    black=im_out[0][0]\n",
    "\n",
    "    im_out[np.where((im_out == black).all(axis = 2))] = [0,0,0]\n",
    "    im_out = cv2.erode(im_out, kernel, iterations=5)\n",
    "    \n",
    "\n",
    "    # The below segment we use will use the mask generated above to extract pixels of apparel and make the rest of\n",
    "    #the pixels transparent.We use transparent because it will be easy for us to filter them out during the \n",
    "    #k-means clustering.\n",
    "    \n",
    "    res =cv2.bitwise_and(src1 = img3, src2 = im_out)\n",
    "\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_RGB2RGBA)\n",
    "    \n",
    "    # making the black background transparent.\n",
    "    res[np.where((im_out == [0,0,0]).all(axis = 2))] = [255,255,255,0]\n",
    "    \n",
    "    # reshaping the array to feed it into the k-means algorithm.\n",
    "    res = res.reshape((res.shape[0] * res.shape[1], 4))\n",
    "    \n",
    "    #extracting only the color pixels leaving behind the transparent pixels.\n",
    "    res = [x for x in res if x[3] != 0]\n",
    "    \n",
    "\n",
    "    #my system struggles ,that's why i shuffled the pixel array and took 1/3th of the sample,results will be more\n",
    "    #accuratte with all pixel values.Just comment the si part and remove sample_size from silhouette_score.\n",
    "    \n",
    "    si=len(res)//4\n",
    "    np.random.shuffle(res)\n",
    "\n",
    "    range_n_clusters = list (range(2,8))\n",
    "\n",
    "    plist=[]\n",
    "    for n_clusters in range_n_clusters:\n",
    "        clusterer = KMeans (n_clusters=n_clusters)\n",
    "        preds = clusterer.fit_predict(res)\n",
    "        centers = clusterer.cluster_centers_\n",
    "        score = silhouette_score (res, preds, sample_size=si,metric='euclidean')\n",
    "        plist.append([n_clusters, score])\n",
    "\n",
    "    def Sort(sub_li): \n",
    "\n",
    "        # reverse = None (Sorts in Descending order) \n",
    "        # key is set to sort using second element of  \n",
    "        # sublist lambda has been used \n",
    "        sub_li.sort(key = lambda x: x[1],reverse=True) \n",
    "        return sub_li \n",
    "\n",
    "    print(Sort(plist))  \n",
    "    clt=plist[0][0]\n",
    "\n",
    "    # cluster the pixel intensities\n",
    "    clt = KMeans(n_clusters = clt)\n",
    "    clt.fit(res)\n",
    "\n",
    "    # build a histogram of clusters and then create a figure\n",
    "    # representing the number of pixels labeled to each color\n",
    "    hist = centroid_histogram(clt)\n",
    "    bar = plot_colors(hist, clt.cluster_centers_)\n",
    "    \n",
    "    \n",
    "    img1 = cv2.imread(f)\n",
    "    img2 = bar\n",
    "\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    #create empty matrix\n",
    "    vis = np.zeros((max(h1, h2), w1+w2,3), np.uint8)\n",
    "\n",
    "    #combine 2 images\n",
    "    vis[:h1, :w1,:3] = img1\n",
    "    vis[:h2, w1:w1+w2,:3] = img2\n",
    "\n",
    "\n",
    "    cv2.imwrite(os.path.join(fileout+'Foreground'+ f2 +'.png'), vis)\n",
    "#     cv2.imshow(\"img1\",vis)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
